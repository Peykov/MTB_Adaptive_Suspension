{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO \n",
    "- We need object detecion(localization) and classification, that's why we need YOLO not a simple Image Classigication CNN. We will need to compute a velocity and direction of the object ( bump, jump, turn) in order to predict the optimal suspension settings.\n",
    "- You only look once. One forward propagation -> Speed. Speed is vital in real-time applications.\n",
    "- Its lightness as a solution and speed of processing is what stands out in comparison to other object detection algorithms as R-CNN or SSD.\n",
    "\n",
    "- IOU - Intesection over union = intersect area / union area ( also called non-max suppression)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Introduction Object Detection\n",
    "\n",
    "1. Difference between Object Classification, Object Detection and Object Recognition\n",
    "\n",
    "\n",
    "    - Object Classification: Classify the object in the image - input is a image and output is a class label\n",
    "    - Object Detection: Detect the object in the image - input is a image and output is a bounding box (x, y, w, h) and a class label\n",
    "    - Object Segmentation: Type of image recognition that identifies and separate the distinct objects in an image on a pixel level (exact shape)\n",
    "\n",
    "2. Brief History\n",
    "\n",
    "    - In the begining Edge Detection techniques were used to detect the object in the image ( Sobel, Canny, Laplacian, etc.)\n",
    "    - First Object Detection Algorithm: Viola Jones (2001)\n",
    "        - Using sliding windows for detecting Haar Features \n",
    "    - Histrogram of Oriented Gradients (HOG) (2005)\n",
    "        - Extracting the gradient and orientation of the edges, mostly used to detec humans\n",
    "    - Deep Learning (2012) ( CNN's) Alex Net, but it was Classification oriented not Detection\n",
    "    - RCNN ( Regions with Convolutional Neural Networks) (2014)\n",
    "        - Selective Search Algorithm to extract the regions of interest and then classify them using CNN\n",
    "        - It was slow and not real time, than Fast RCNN and Faster - RCNN was introduced\n",
    "        \n",
    "    - **YOLO** ( You Only Look Once) (2015) - Real time\n",
    "    - Supervised ML model\n",
    "    - Single pass to predict, while RCNN needs multiple iterrations one after another \n",
    "    \n",
    "3. Evaluation\n",
    "\n",
    "- How good is the location:\n",
    "    - IoU - Intersection over Union (how close the predicted bounding box is to the ground truth bounding box) (value between 0-1)\n",
    "\n",
    "- How good is the classification\n",
    "    - mAP - mean Average Precision\n",
    "    - AP - Average Precision ( confusion matrix, precssion and recall )\n",
    "        - Precision - Actual Positives out of total positive predictions ( True Positive / ( True Postives + False Postives))\n",
    "        - Recall - Actual positives out of all predictions ( True Postives / (True Postives + False Negatives)) \n",
    "        - Area under the Recall-Precision Curve \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOLO Testing and Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "results = model('images/1.jpg', stream=True)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO with WebCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 154.1ms\n",
      "Speed: 3.1ms preprocess, 154.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 363.0ms\n",
      "Speed: 6.7ms preprocess, 363.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 228.0ms\n",
      "Speed: 5.0ms preprocess, 228.0ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 177.4ms\n",
      "Speed: 5.6ms preprocess, 177.4ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 143.0ms\n",
      "Speed: 2.5ms preprocess, 143.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 137.5ms\n",
      "Speed: 4.4ms preprocess, 137.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 144.9ms\n",
      "Speed: 3.4ms preprocess, 144.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 132.9ms\n",
      "Speed: 5.0ms preprocess, 132.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 140.9ms\n",
      "Speed: 3.5ms preprocess, 140.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 140.6ms\n",
      "Speed: 3.9ms preprocess, 140.6ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 137.5ms\n",
      "Speed: 2.0ms preprocess, 137.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 129.4ms\n",
      "Speed: 4.5ms preprocess, 129.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 129.7ms\n",
      "Speed: 4.0ms preprocess, 129.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 124.9ms\n",
      "Speed: 3.0ms preprocess, 124.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 137.4ms\n",
      "Speed: 2.4ms preprocess, 137.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 140.9ms\n",
      "Speed: 2.5ms preprocess, 140.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 142.6ms\n",
      "Speed: 2.0ms preprocess, 142.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 136.5ms\n",
      "Speed: 4.0ms preprocess, 136.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 136.1ms\n",
      "Speed: 4.3ms preprocess, 136.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 137.0ms\n",
      "Speed: 3.0ms preprocess, 137.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 133.0ms\n",
      "Speed: 2.5ms preprocess, 133.0ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 138.7ms\n",
      "Speed: 4.1ms preprocess, 138.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 141.5ms\n",
      "Speed: 3.3ms preprocess, 141.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 donut, 140.2ms\n",
      "Speed: 3.5ms preprocess, 140.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 129.8ms\n",
      "Speed: 3.0ms preprocess, 129.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 132.7ms\n",
      "Speed: 3.2ms preprocess, 132.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 123.7ms\n",
      "Speed: 2.3ms preprocess, 123.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 189.1ms\n",
      "Speed: 3.1ms preprocess, 189.1ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 137.0ms\n",
      "Speed: 4.0ms preprocess, 137.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 154.2ms\n",
      "Speed: 3.0ms preprocess, 154.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 137.6ms\n",
      "Speed: 4.5ms preprocess, 137.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 144.3ms\n",
      "Speed: 3.0ms preprocess, 144.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 142.3ms\n",
      "Speed: 6.0ms preprocess, 142.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 148.5ms\n",
      "Speed: 3.2ms preprocess, 148.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 138.1ms\n",
      "Speed: 3.1ms preprocess, 138.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 133.7ms\n",
      "Speed: 3.5ms preprocess, 133.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 132.8ms\n",
      "Speed: 3.0ms preprocess, 132.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 138.7ms\n",
      "Speed: 3.0ms preprocess, 138.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.0ms\n",
      "Speed: 2.8ms preprocess, 136.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 141.0ms\n",
      "Speed: 4.0ms preprocess, 141.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 136.1ms\n",
      "Speed: 3.3ms preprocess, 136.1ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 140.3ms\n",
      "Speed: 4.2ms preprocess, 140.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 134.7ms\n",
      "Speed: 3.5ms preprocess, 134.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 131.5ms\n",
      "Speed: 4.1ms preprocess, 131.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 133.1ms\n",
      "Speed: 3.2ms preprocess, 133.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 154.4ms\n",
      "Speed: 2.6ms preprocess, 154.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 141.5ms\n",
      "Speed: 3.7ms preprocess, 141.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 132.6ms\n",
      "Speed: 2.2ms preprocess, 132.6ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 135.0ms\n",
      "Speed: 4.2ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 135.3ms\n",
      "Speed: 4.5ms preprocess, 135.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 130.3ms\n",
      "Speed: 3.0ms preprocess, 130.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 130.4ms\n",
      "Speed: 2.0ms preprocess, 130.4ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 131.2ms\n",
      "Speed: 3.3ms preprocess, 131.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 chair, 176.9ms\n",
      "Speed: 2.7ms preprocess, 176.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 132.6ms\n",
      "Speed: 5.0ms preprocess, 132.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 133.9ms\n",
      "Speed: 2.1ms preprocess, 133.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 135.6ms\n",
      "Speed: 4.4ms preprocess, 135.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 133.9ms\n",
      "Speed: 3.0ms preprocess, 133.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 135.2ms\n",
      "Speed: 2.4ms preprocess, 135.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 135.7ms\n",
      "Speed: 3.0ms preprocess, 135.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 136.2ms\n",
      "Speed: 4.0ms preprocess, 136.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 144.1ms\n",
      "Speed: 3.0ms preprocess, 144.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 161.0ms\n",
      "Speed: 3.0ms preprocess, 161.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 181.9ms\n",
      "Speed: 3.2ms preprocess, 181.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 210.9ms\n",
      "Speed: 6.1ms preprocess, 210.9ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 220.3ms\n",
      "Speed: 3.9ms preprocess, 220.3ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 266.2ms\n",
      "Speed: 4.0ms preprocess, 266.2ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 235.3ms\n",
      "Speed: 6.7ms preprocess, 235.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 258.1ms\n",
      "Speed: 5.0ms preprocess, 258.1ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 227.1ms\n",
      "Speed: 4.4ms preprocess, 227.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 237.5ms\n",
      "Speed: 4.6ms preprocess, 237.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 238.2ms\n",
      "Speed: 4.1ms preprocess, 238.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 231.0ms\n",
      "Speed: 7.1ms preprocess, 231.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 235.5ms\n",
      "Speed: 6.3ms preprocess, 235.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 243.7ms\n",
      "Speed: 5.6ms preprocess, 243.7ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 1 cell phone, 229.1ms\n",
      "Speed: 5.0ms preprocess, 229.1ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cell phones, 312.6ms\n",
      "Speed: 6.1ms preprocess, 312.6ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cell phones, 258.0ms\n",
      "Speed: 5.2ms preprocess, 258.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 245.0ms\n",
      "Speed: 4.3ms preprocess, 245.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 209.5ms\n",
      "Speed: 5.9ms preprocess, 209.5ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 250.3ms\n",
      "Speed: 4.5ms preprocess, 250.3ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 218.9ms\n",
      "Speed: 4.7ms preprocess, 218.9ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 221.4ms\n",
      "Speed: 5.8ms preprocess, 221.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 224.9ms\n",
      "Speed: 2.1ms preprocess, 224.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 201.8ms\n",
      "Speed: 6.5ms preprocess, 201.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 205.6ms\n",
      "Speed: 4.3ms preprocess, 205.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 198.4ms\n",
      "Speed: 4.0ms preprocess, 198.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 204.8ms\n",
      "Speed: 3.5ms preprocess, 204.8ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 188.8ms\n",
      "Speed: 6.0ms preprocess, 188.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 187.3ms\n",
      "Speed: 3.2ms preprocess, 187.3ms inference, 5.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 244.2ms\n",
      "Speed: 2.3ms preprocess, 244.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 209.4ms\n",
      "Speed: 4.8ms preprocess, 209.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 218.5ms\n",
      "Speed: 5.1ms preprocess, 218.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 195.6ms\n",
      "Speed: 4.0ms preprocess, 195.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 190.6ms\n",
      "Speed: 5.0ms preprocess, 190.6ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 4 persons, 206.0ms\n",
      "Speed: 4.0ms preprocess, 206.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 223.8ms\n",
      "Speed: 6.9ms preprocess, 223.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.5ms\n",
      "Speed: 5.3ms preprocess, 252.5ms inference, 5.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.8ms\n",
      "Speed: 6.6ms preprocess, 216.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 217.8ms\n",
      "Speed: 4.0ms preprocess, 217.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 205.0ms\n",
      "Speed: 4.5ms preprocess, 205.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 200.9ms\n",
      "Speed: 5.0ms preprocess, 200.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 200.5ms\n",
      "Speed: 7.0ms preprocess, 200.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 203.0ms\n",
      "Speed: 5.7ms preprocess, 203.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 196.4ms\n",
      "Speed: 5.7ms preprocess, 196.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 187.9ms\n",
      "Speed: 3.5ms preprocess, 187.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 195.8ms\n",
      "Speed: 3.5ms preprocess, 195.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 197.5ms\n",
      "Speed: 4.1ms preprocess, 197.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 188.0ms\n",
      "Speed: 5.0ms preprocess, 188.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 207.2ms\n",
      "Speed: 3.0ms preprocess, 207.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 212.6ms\n",
      "Speed: 6.6ms preprocess, 212.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 233.2ms\n",
      "Speed: 5.0ms preprocess, 233.2ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 remote, 223.0ms\n",
      "Speed: 5.2ms preprocess, 223.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 204.7ms\n",
      "Speed: 5.6ms preprocess, 204.7ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 201.3ms\n",
      "Speed: 3.5ms preprocess, 201.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 218.5ms\n",
      "Speed: 5.5ms preprocess, 218.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 193.2ms\n",
      "Speed: 4.0ms preprocess, 193.2ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 194.3ms\n",
      "Speed: 4.3ms preprocess, 194.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 227.3ms\n",
      "Speed: 4.3ms preprocess, 227.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 300.4ms\n",
      "Speed: 4.5ms preprocess, 300.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 242.3ms\n",
      "Speed: 4.2ms preprocess, 242.3ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 222.6ms\n",
      "Speed: 5.5ms preprocess, 222.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 202.5ms\n",
      "Speed: 5.6ms preprocess, 202.5ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 213.4ms\n",
      "Speed: 4.8ms preprocess, 213.4ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 192.0ms\n",
      "Speed: 4.0ms preprocess, 192.0ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 207.8ms\n",
      "Speed: 5.5ms preprocess, 207.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 220.1ms\n",
      "Speed: 3.5ms preprocess, 220.1ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 189.8ms\n",
      "Speed: 4.5ms preprocess, 189.8ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 202.6ms\n",
      "Speed: 3.2ms preprocess, 202.6ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 206.4ms\n",
      "Speed: 4.0ms preprocess, 206.4ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 203.1ms\n",
      "Speed: 3.5ms preprocess, 203.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 tennis racket, 206.7ms\n",
      "Speed: 4.9ms preprocess, 206.7ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 203.2ms\n",
      "Speed: 4.6ms preprocess, 203.2ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 205.9ms\n",
      "Speed: 4.6ms preprocess, 205.9ms inference, 3.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 200.6ms\n",
      "Speed: 3.0ms preprocess, 200.6ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 185.9ms\n",
      "Speed: 3.9ms preprocess, 185.9ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 204.9ms\n",
      "Speed: 3.9ms preprocess, 204.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 201.0ms\n",
      "Speed: 4.0ms preprocess, 201.0ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 200.1ms\n",
      "Speed: 5.5ms preprocess, 200.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 195.1ms\n",
      "Speed: 5.9ms preprocess, 195.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 199.0ms\n",
      "Speed: 4.0ms preprocess, 199.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.0ms\n",
      "Speed: 5.5ms preprocess, 245.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 197.6ms\n",
      "Speed: 5.0ms preprocess, 197.6ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 3 persons, 203.4ms\n",
      "Speed: 4.4ms preprocess, 203.4ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 219.7ms\n",
      "Speed: 4.2ms preprocess, 219.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 223.4ms\n",
      "Speed: 6.6ms preprocess, 223.4ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 228.0ms\n",
      "Speed: 4.5ms preprocess, 228.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 219.0ms\n",
      "Speed: 6.5ms preprocess, 219.0ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 214.4ms\n",
      "Speed: 6.6ms preprocess, 214.4ms inference, 6.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 236.3ms\n",
      "Speed: 4.0ms preprocess, 236.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 220.0ms\n",
      "Speed: 7.3ms preprocess, 220.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 197.9ms\n",
      "Speed: 5.7ms preprocess, 197.9ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.0ms\n",
      "Speed: 4.0ms preprocess, 252.0ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 237.1ms\n",
      "Speed: 4.5ms preprocess, 237.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 238.4ms\n",
      "Speed: 4.7ms preprocess, 238.4ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 251.7ms\n",
      "Speed: 4.5ms preprocess, 251.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 2 persons, 271.3ms\n",
      "Speed: 5.2ms preprocess, 271.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    results = model(img, stream=True)\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "                # Bounding Box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                bbox = (x1, y1, w, h)\n",
    "                # cv2.rectangle(image, (x1, y1), (x2, y2), (150, 0, 255), 1)\n",
    "                cvzone.cornerRect(img, (bbox), 20, rt = 2)\n",
    "                # Confidence\n",
    "                conf = math.ceil((box.conf[0] * 100))/100\n",
    "                cvzone.putTextRect(img, f'{conf}', (max(0, x1), max(35, y1)), 1, 1)\n",
    "\n",
    "                # Class Name\n",
    "                cls = int(box.cls[0])\n",
    "                cvzone.putTextRect(img, f'{classNames[cls]}', (max(0, x1 + 50), max(35, y1)), scale=1, thickness=1)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # break the loop on 'q' key press\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Capture a single frame\n",
    "ret, frame = cap.read()  \n",
    "# Save the frame to a file\n",
    "if ret:\n",
    "    cv2.imwrite('frame.png', frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 persons, 2 buss, 2 backpacks, 1 handbag, 198.3ms\n",
      "Speed: 7.0ms preprocess, 198.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread('1.png')\n",
    "results = model(image, show = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "                # Bounding Box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                bbox = (x1, y1, w, h)\n",
    "                # cv2.rectangle(image, (x1, y1), (x2, y2), (150, 0, 255), 1)\n",
    "                cvzone.cornerRect(image, (bbox), 20, rt = 2)\n",
    "                # Confidence\n",
    "                conf = math.ceil((box.conf[0] * 100))/100\n",
    "                cvzone.putTextRect(image, f'{conf}', (max(0, x1), max(35, y1)), 1, 1)\n",
    "\n",
    "                # Class Name\n",
    "                cls = int(box.cls[0])\n",
    "                cvzone.putTextRect(image, f'{classNames[cls]}', (max(0, x1 + 50), max(35, y1)), scale=1, thickness=1)\n",
    "\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training YOLO on Custom Dataset in Google Colab using GPU\n",
    "- Construction_safety dataset: Train, Valid, Test images and labels\n",
    "\n",
    "    - **Training set**: This is the largest set and is what we use to train our model. The model learns from these examples.\n",
    "\n",
    "    - **Validation set**: This is used to validate the results from the training process. After each epoch (or a certain number of iterations) of training, the model's performance is evaluated on the validation set. This helps monitor the model's learning progress and can also be useful to tune hyperparameters, choose the best version of the model, and prevent overfitting. If a model performs well on the training set but poorly on the validation set, it may be overfitting to the training data.\n",
    "\n",
    "    - **Test set**: The test set is used only once, after the model has been completely trained. This set is used to get an unbiased evaluation of the final model, to assess how well the model generalizes to unseen data.\n",
    "\n",
    "![Alt](COLABtrain0.png)\n",
    "![Alt](COLABtrain1.png)\n",
    "\n",
    "- ### Results: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from Colab for training \n",
    "\n",
    "from ultralytics import YOLO\n",
    "!yolo task=detect mode=train model=yolov8l.pt data=../content/drive/MyDrive/Colab_Notebooks/YOLO/Construction_Safety/data.yaml epochs=50 imgsz=640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 1679.8ms\n",
      "Speed: 6.7ms preprocess, 1679.8ms inference, 5.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 4583.0ms\n",
      "Speed: 9.1ms preprocess, 4583.0ms inference, 9.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 5511.0ms\n",
      "Speed: 13.7ms preprocess, 5511.0ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 5771.3ms\n",
      "Speed: 12.7ms preprocess, 5771.3ms inference, 14.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 4417.7ms\n",
      "Speed: 15.6ms preprocess, 4417.7ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 3801.3ms\n",
      "Speed: 11.2ms preprocess, 3801.3ms inference, 7.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 3652.5ms\n",
      "Speed: 10.2ms preprocess, 3652.5ms inference, 6.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 NO-Safety Vest, 1 Person, 1 Safety Vest, 5009.9ms\n",
      "Speed: 9.6ms preprocess, 5009.9ms inference, 4.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 384x640 1 Hardhat, 1 NO-Mask, 1 Person, 1 Safety Vest, 3396.8ms\n",
      "Speed: 12.4ms preprocess, 3396.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# We are downloading the weights (best.pt) from the colab and saving it in the local directory\n",
    "\n",
    "cap = cv2.VideoCapture(\"ppe-1.mp4\")\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "classNames = ['Hardhat', 'Mask', 'NO-Hardhat', 'NO-Mask', 'NO-Safety Vest', 'Person', 'Safety Cone', 'Safety Vest', 'machinery', 'vehicle']\n",
    "\n",
    "MyColor = (0, 0, 255)\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    results = model(img, stream=True)\n",
    "    \n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "                # Bounding Box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                bbox = (x1, y1, w, h)\n",
    "                # cv2.rectangle(image, (x1, y1), (x2, y2), (150, 0, 255), 1)\n",
    "                cvzone.cornerRect(img, (bbox), 20, rt = 2)\n",
    "                \n",
    "\n",
    "                # Confidence\n",
    "                conf = math.ceil((box.conf[0] * 100))/100\n",
    "            \n",
    "                # Class Name\n",
    "                cls = int(box.cls[0])\n",
    "                currentClass = classNames[cls]\n",
    "\n",
    "                if conf > 0.5:\n",
    "\n",
    "                    if currentClass == 'Hardhat' or currentClass == 'Mask' or currentClass == 'Safety Vest':\n",
    "                        MyColor = (0, 255, 0)\n",
    "                    elif currentClass == 'NO-Hardhat' or currentClass == 'NO-Mask' or currentClass == 'NO-Safety Vest':\n",
    "                        MyColor = (0, 0, 255)\n",
    "                    else :\n",
    "                        MyColor = (255, 0, 0)\n",
    "\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), MyColor, 3)\n",
    "                cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1 + 50), max(35, y1)), scale=0.8, thickness=1, colorB=MyColor, colorT= (255, 255, 255), colorR=MyColor, offset=5)\n",
    "\n",
    "                \n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # break the loop on 'q' key press\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation of Custom Dataset for MTB Trail Detection\n",
    "\n",
    "- Selecting usefull frames from GoPro video\n",
    "- Labeling the images using LabelImg software and auto\n",
    "\n",
    "- After the assesment that typical object detection model like **YOLO** might not be the best choice for this problem because there aren't clear, discrete objects to detect.\n",
    "- Considering the possibility of using **Semantic Segmentation** instead of Object Detection\n",
    "\n",
    "- ### Would Action recognition be a better choice for this problem ??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from Colab for training \n",
    "# Here we have probles with duplciation run of a library but in Colab the training went fine\n",
    "\n",
    "from ultralytics import YOLO\n",
    "!yolo task=detect mode=train model='yolov8l.pt' data=../MTB_dataset/data.yaml epochs=10 imgsz=700"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.jpg](results.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 416x704 7 jumps, 1 turn, 1319.6ms\n",
      "Speed: 4.7ms preprocess, 1319.6ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 1 turn, 1200.6ms\n",
      "Speed: 5.7ms preprocess, 1200.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 5 jumps, 2 turns, 1151.6ms\n",
      "Speed: 4.9ms preprocess, 1151.6ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 2 turns, 1122.9ms\n",
      "Speed: 4.1ms preprocess, 1122.9ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 1 turn, 1158.5ms\n",
      "Speed: 4.3ms preprocess, 1158.5ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 2 turns, 1234.3ms\n",
      "Speed: 4.5ms preprocess, 1234.3ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 4 turns, 1105.6ms\n",
      "Speed: 5.4ms preprocess, 1105.6ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 4 turns, 1206.3ms\n",
      "Speed: 3.1ms preprocess, 1206.3ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 7 jumps, 5 turns, 1175.7ms\n",
      "Speed: 4.2ms preprocess, 1175.7ms inference, 1.1ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 5 turns, 1203.1ms\n",
      "Speed: 4.0ms preprocess, 1203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 7 turns, 1188.6ms\n",
      "Speed: 4.0ms preprocess, 1188.6ms inference, 2.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 9 turns, 1877.2ms\n",
      "Speed: 13.6ms preprocess, 1877.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 7 turns, 1919.1ms\n",
      "Speed: 6.6ms preprocess, 1919.1ms inference, 2.1ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 11 turns, 1917.6ms\n",
      "Speed: 9.4ms preprocess, 1917.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 11 turns, 1709.6ms\n",
      "Speed: 6.6ms preprocess, 1709.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 9 turns, 1769.0ms\n",
      "Speed: 6.2ms preprocess, 1769.0ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 11 turns, 1908.3ms\n",
      "Speed: 7.5ms preprocess, 1908.3ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 12 turns, 1753.6ms\n",
      "Speed: 6.8ms preprocess, 1753.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 11 turns, 1726.4ms\n",
      "Speed: 6.4ms preprocess, 1726.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 10 turns, 1752.7ms\n",
      "Speed: 5.6ms preprocess, 1752.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 15 turns, 1739.6ms\n",
      "Speed: 8.0ms preprocess, 1739.6ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 11 turns, 1835.8ms\n",
      "Speed: 6.4ms preprocess, 1835.8ms inference, 2.1ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 13 turns, 1788.6ms\n",
      "Speed: 7.3ms preprocess, 1788.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 1793.6ms\n",
      "Speed: 6.5ms preprocess, 1793.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 12 turns, 1940.9ms\n",
      "Speed: 5.0ms preprocess, 1940.9ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 turns, 1713.3ms\n",
      "Speed: 9.2ms preprocess, 1713.3ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 1825.1ms\n",
      "Speed: 7.4ms preprocess, 1825.1ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 8 turns, 1700.2ms\n",
      "Speed: 6.3ms preprocess, 1700.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 9 turns, 1744.5ms\n",
      "Speed: 5.0ms preprocess, 1744.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 8 turns, 1687.7ms\n",
      "Speed: 5.9ms preprocess, 1687.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 8 turns, 1741.1ms\n",
      "Speed: 6.1ms preprocess, 1741.1ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 11 turns, 1807.9ms\n",
      "Speed: 5.4ms preprocess, 1807.9ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 11 turns, 1715.4ms\n",
      "Speed: 5.1ms preprocess, 1715.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 8 turns, 1708.0ms\n",
      "Speed: 7.6ms preprocess, 1708.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 1696.9ms\n",
      "Speed: 5.1ms preprocess, 1696.9ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 1750.7ms\n",
      "Speed: 6.0ms preprocess, 1750.7ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 1753.9ms\n",
      "Speed: 5.4ms preprocess, 1753.9ms inference, 2.4ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 9 turns, 1700.2ms\n",
      "Speed: 9.0ms preprocess, 1700.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 1697.5ms\n",
      "Speed: 7.5ms preprocess, 1697.5ms inference, 2.4ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 8 turns, 1686.7ms\n",
      "Speed: 4.6ms preprocess, 1686.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 8 turns, 1697.0ms\n",
      "Speed: 5.0ms preprocess, 1697.0ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 9 turns, 1837.3ms\n",
      "Speed: 11.8ms preprocess, 1837.3ms inference, 3.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 3 turns, 1758.8ms\n",
      "Speed: 6.0ms preprocess, 1758.8ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2 turns, 1791.1ms\n",
      "Speed: 5.4ms preprocess, 1791.1ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 1770.6ms\n",
      "Speed: 5.8ms preprocess, 1770.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 1706.3ms\n",
      "Speed: 6.0ms preprocess, 1706.3ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 5 turns, 1813.2ms\n",
      "Speed: 7.1ms preprocess, 1813.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 7 turns, 1794.2ms\n",
      "Speed: 7.3ms preprocess, 1794.2ms inference, 3.7ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 1824.7ms\n",
      "Speed: 7.6ms preprocess, 1824.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 1806.7ms\n",
      "Speed: 6.5ms preprocess, 1806.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 6 turns, 1704.6ms\n",
      "Speed: 6.0ms preprocess, 1704.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 8 turns, 1774.3ms\n",
      "Speed: 5.1ms preprocess, 1774.3ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 11 turns, 1686.0ms\n",
      "Speed: 6.8ms preprocess, 1686.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 9 turns, 1780.6ms\n",
      "Speed: 6.1ms preprocess, 1780.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 7 turns, 1772.1ms\n",
      "Speed: 6.3ms preprocess, 1772.1ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 8 turns, 1828.2ms\n",
      "Speed: 7.4ms preprocess, 1828.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 11 turns, 1887.0ms\n",
      "Speed: 9.2ms preprocess, 1887.0ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 10 turns, 1747.0ms\n",
      "Speed: 5.0ms preprocess, 1747.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 9 turns, 1713.1ms\n",
      "Speed: 9.0ms preprocess, 1713.1ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 1826.6ms\n",
      "Speed: 6.3ms preprocess, 1826.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2000.9ms\n",
      "Speed: 8.3ms preprocess, 2000.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2124.5ms\n",
      "Speed: 7.5ms preprocess, 2124.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1 turn, 2124.6ms\n",
      "Speed: 7.0ms preprocess, 2124.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2517.5ms\n",
      "Speed: 8.0ms preprocess, 2517.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2357.4ms\n",
      "Speed: 11.9ms preprocess, 2357.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 1 turn, 2101.9ms\n",
      "Speed: 10.1ms preprocess, 2101.9ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1 turn, 2317.0ms\n",
      "Speed: 7.4ms preprocess, 2317.0ms inference, 3.1ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2487.4ms\n",
      "Speed: 9.0ms preprocess, 2487.4ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2702.9ms\n",
      "Speed: 43.9ms preprocess, 2702.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2361.8ms\n",
      "Speed: 9.3ms preprocess, 2361.8ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 1 turn, 2067.2ms\n",
      "Speed: 7.0ms preprocess, 2067.2ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 3 turns, 2541.8ms\n",
      "Speed: 8.0ms preprocess, 2541.8ms inference, 2.7ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2 turns, 2725.1ms\n",
      "Speed: 14.0ms preprocess, 2725.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2813.5ms\n",
      "Speed: 9.0ms preprocess, 2813.5ms inference, 3.3ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1 turn, 2329.6ms\n",
      "Speed: 9.5ms preprocess, 2329.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 turn, 2432.7ms\n",
      "Speed: 9.0ms preprocess, 2432.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2585.0ms\n",
      "Speed: 9.5ms preprocess, 2585.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2638.9ms\n",
      "Speed: 7.1ms preprocess, 2638.9ms inference, 1.3ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2689.5ms\n",
      "Speed: 12.0ms preprocess, 2689.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2362.3ms\n",
      "Speed: 7.5ms preprocess, 2362.3ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2566.9ms\n",
      "Speed: 9.0ms preprocess, 2566.9ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2630.6ms\n",
      "Speed: 9.0ms preprocess, 2630.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1 turn, 2389.0ms\n",
      "Speed: 10.0ms preprocess, 2389.0ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 1 turn, 2477.5ms\n",
      "Speed: 9.0ms preprocess, 2477.5ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2586.0ms\n",
      "Speed: 10.2ms preprocess, 2586.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2664.5ms\n",
      "Speed: 8.0ms preprocess, 2664.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2578.6ms\n",
      "Speed: 11.5ms preprocess, 2578.6ms inference, 2.8ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2783.4ms\n",
      "Speed: 9.8ms preprocess, 2783.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 turn, 2231.4ms\n",
      "Speed: 8.0ms preprocess, 2231.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 turn, 2031.8ms\n",
      "Speed: 6.8ms preprocess, 2031.8ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2309.3ms\n",
      "Speed: 7.0ms preprocess, 2309.3ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2054.0ms\n",
      "Speed: 6.0ms preprocess, 2054.0ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1 turn, 2091.7ms\n",
      "Speed: 11.1ms preprocess, 2091.7ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 1 turn, 2136.9ms\n",
      "Speed: 6.8ms preprocess, 2136.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2 turns, 2438.6ms\n",
      "Speed: 8.6ms preprocess, 2438.6ms inference, 4.3ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2619.1ms\n",
      "Speed: 8.5ms preprocess, 2619.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 turn, 2139.5ms\n",
      "Speed: 9.0ms preprocess, 2139.5ms inference, 2.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 1 turn, 2215.1ms\n",
      "Speed: 8.0ms preprocess, 2215.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2052.8ms\n",
      "Speed: 6.0ms preprocess, 2052.8ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2154.6ms\n",
      "Speed: 6.3ms preprocess, 2154.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2058.2ms\n",
      "Speed: 8.1ms preprocess, 2058.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1811.9ms\n",
      "Speed: 7.0ms preprocess, 1811.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 1887.4ms\n",
      "Speed: 6.5ms preprocess, 1887.4ms inference, 2.9ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 1 turn, 1828.5ms\n",
      "Speed: 7.0ms preprocess, 1828.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2 turns, 1939.8ms\n",
      "Speed: 6.4ms preprocess, 1939.8ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2497.5ms\n",
      "Speed: 6.1ms preprocess, 2497.5ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2809.4ms\n",
      "Speed: 8.7ms preprocess, 2809.4ms inference, 1.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 (no detections), 2554.4ms\n",
      "Speed: 9.9ms preprocess, 2554.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2566.9ms\n",
      "Speed: 10.0ms preprocess, 2566.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2389.8ms\n",
      "Speed: 8.3ms preprocess, 2389.8ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 turn, 2218.2ms\n",
      "Speed: 10.1ms preprocess, 2218.2ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 turns, 1909.1ms\n",
      "Speed: 7.4ms preprocess, 1909.1ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 turns, 1835.9ms\n",
      "Speed: 5.5ms preprocess, 1835.9ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 1941.2ms\n",
      "Speed: 7.2ms preprocess, 1941.2ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 1957.0ms\n",
      "Speed: 6.0ms preprocess, 1957.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 6 turns, 2191.4ms\n",
      "Speed: 7.0ms preprocess, 2191.4ms inference, 2.6ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 2103.3ms\n",
      "Speed: 9.5ms preprocess, 2103.3ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 2291.8ms\n",
      "Speed: 6.3ms preprocess, 2291.8ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 3 turns, 2431.8ms\n",
      "Speed: 8.0ms preprocess, 2431.8ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 2666.4ms\n",
      "Speed: 9.0ms preprocess, 2666.4ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2917.6ms\n",
      "Speed: 10.0ms preprocess, 2917.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 7 turns, 3199.2ms\n",
      "Speed: 8.1ms preprocess, 3199.2ms inference, 5.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 6 turns, 2906.9ms\n",
      "Speed: 15.1ms preprocess, 2906.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 2540.7ms\n",
      "Speed: 7.0ms preprocess, 2540.7ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 6 turns, 2535.2ms\n",
      "Speed: 10.8ms preprocess, 2535.2ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 7 turns, 2532.4ms\n",
      "Speed: 8.1ms preprocess, 2532.4ms inference, 2.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 2376.3ms\n",
      "Speed: 8.1ms preprocess, 2376.3ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 7 turns, 2551.0ms\n",
      "Speed: 10.0ms preprocess, 2551.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 2556.7ms\n",
      "Speed: 8.9ms preprocess, 2556.7ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 2350.9ms\n",
      "Speed: 8.3ms preprocess, 2350.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 4 turns, 2633.1ms\n",
      "Speed: 7.5ms preprocess, 2633.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 8 turns, 2480.9ms\n",
      "Speed: 8.0ms preprocess, 2480.9ms inference, 4.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 3 turns, 2655.7ms\n",
      "Speed: 8.1ms preprocess, 2655.7ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 10 turns, 2170.6ms\n",
      "Speed: 6.2ms preprocess, 2170.6ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 2067.0ms\n",
      "Speed: 7.2ms preprocess, 2067.0ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 turns, 2626.6ms\n",
      "Speed: 8.0ms preprocess, 2626.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 turns, 2505.8ms\n",
      "Speed: 9.0ms preprocess, 2505.8ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 turns, 2307.4ms\n",
      "Speed: 10.0ms preprocess, 2307.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 2509.6ms\n",
      "Speed: 8.0ms preprocess, 2509.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 2527.0ms\n",
      "Speed: 9.0ms preprocess, 2527.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 1 turn, 2504.1ms\n",
      "Speed: 8.1ms preprocess, 2504.1ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 1 turn, 2016.9ms\n",
      "Speed: 7.1ms preprocess, 2016.9ms inference, 2.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 3 turns, 2176.4ms\n",
      "Speed: 6.5ms preprocess, 2176.4ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2 turns, 2493.9ms\n",
      "Speed: 8.8ms preprocess, 2493.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2470.3ms\n",
      "Speed: 10.0ms preprocess, 2470.3ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 7 turns, 2611.9ms\n",
      "Speed: 7.2ms preprocess, 2611.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 4 turns, 2356.0ms\n",
      "Speed: 10.0ms preprocess, 2356.0ms inference, 1.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 2537.5ms\n",
      "Speed: 10.0ms preprocess, 2537.5ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 turns, 2676.3ms\n",
      "Speed: 11.0ms preprocess, 2676.3ms inference, 2.8ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 3 turns, 2327.5ms\n",
      "Speed: 8.3ms preprocess, 2327.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 3 turns, 2642.7ms\n",
      "Speed: 10.3ms preprocess, 2642.7ms inference, 3.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2481.9ms\n",
      "Speed: 9.4ms preprocess, 2481.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 6 turns, 2577.6ms\n",
      "Speed: 10.0ms preprocess, 2577.6ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 turns, 2308.2ms\n",
      "Speed: 11.0ms preprocess, 2308.2ms inference, 2.3ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 6 turns, 2471.5ms\n",
      "Speed: 7.0ms preprocess, 2471.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 2521.4ms\n",
      "Speed: 10.3ms preprocess, 2521.4ms inference, 2.9ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 2440.7ms\n",
      "Speed: 9.5ms preprocess, 2440.7ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 2572.6ms\n",
      "Speed: 9.2ms preprocess, 2572.6ms inference, 4.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 2 turns, 2626.5ms\n",
      "Speed: 10.0ms preprocess, 2626.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 5 turns, 2192.9ms\n",
      "Speed: 10.3ms preprocess, 2192.9ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 7 turns, 2167.4ms\n",
      "Speed: 7.1ms preprocess, 2167.4ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 6 turns, 2317.7ms\n",
      "Speed: 9.2ms preprocess, 2317.7ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 2274.1ms\n",
      "Speed: 8.0ms preprocess, 2274.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 4 turns, 1974.0ms\n",
      "Speed: 9.0ms preprocess, 1974.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 4 turns, 1881.0ms\n",
      "Speed: 7.0ms preprocess, 1881.0ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 4 turns, 2000.5ms\n",
      "Speed: 7.6ms preprocess, 2000.5ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 4 turns, 2101.9ms\n",
      "Speed: 6.5ms preprocess, 2101.9ms inference, 2.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2050.1ms\n",
      "Speed: 8.5ms preprocess, 2050.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2137.8ms\n",
      "Speed: 8.0ms preprocess, 2137.8ms inference, 2.1ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 3 turns, 1989.6ms\n",
      "Speed: 8.5ms preprocess, 1989.6ms inference, 3.5ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 turns, 2419.5ms\n",
      "Speed: 5.2ms preprocess, 2419.5ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 1 jump, 4 turns, 2627.0ms\n",
      "Speed: 6.6ms preprocess, 2627.0ms inference, 4.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 3 turns, 2605.4ms\n",
      "Speed: 10.0ms preprocess, 2605.4ms inference, 2.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 4 jumps, 6 turns, 2534.1ms\n",
      "Speed: 8.0ms preprocess, 2534.1ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 3 jumps, 4 turns, 2395.3ms\n",
      "Speed: 8.4ms preprocess, 2395.3ms inference, 3.2ms postprocess per image at shape (1, 3, 704, 704)\n",
      "\n",
      "0: 416x704 2 jumps, 5 turns, 2518.9ms\n",
      "Speed: 7.0ms preprocess, 2518.9ms inference, 3.0ms postprocess per image at shape (1, 3, 704, 704)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to capture image\n"
     ]
    }
   ],
   "source": [
    "# We are downloading the weights (bestmb.pt) from the colab and saving it in the local directory\n",
    "\n",
    "cap = cv2.VideoCapture(\"output_cropped.mp4\")\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "out = cv2.VideoWriter('output_with_detections.mp4',cv2.VideoWriter_fourcc(*'mp4v'), 20.0, (frame_width, frame_height))\n",
    "\n",
    "model = YOLO('bestmb.pt')\n",
    "\n",
    "classNames = ['turn', 'jump']\n",
    "\n",
    "MyColor = (0, 0, 255)\n",
    "\n",
    "# img = cv2.imread('../MTB_dataset/test/images/2023-06-08 10_45_19-(190) DARKFEST 2020- WORLDS BIGGEST MTB JUMPS WITH NICO VINK - YouTube.jpg')\n",
    "\n",
    "while True:\n",
    "\n",
    "    success, img = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "                \n",
    "                # Confidence\n",
    "                conf = math.ceil((box.conf[0] * 100))/100\n",
    "\n",
    "                if conf > 0.92:\n",
    "                    # Bounding Box\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    w, h = x2 - x1, y2 - y1\n",
    "                    bbox = (x1, y1, w, h)\n",
    "                    # cv2.rectangle(image, (x1, y1), (x2, y2), (150, 0, 255), 1)\n",
    "                    cvzone.cornerRect(img, (bbox), 20, rt = 2)\n",
    "                    \n",
    "\n",
    "                \n",
    "                    # Class Name\n",
    "                    cls = int(box.cls[0])\n",
    "                    currentClass = classNames[cls]\n",
    "\n",
    "                    # if conf > 0.5:\n",
    "\n",
    "                    #     if currentClass == 'Hardhat' or currentClass == 'Mask' or currentClass == 'Safety Vest':\n",
    "                    #         MyColor = (0, 255, 0)\n",
    "                    #     elif currentClass == 'NO-Hardhat' or currentClass == 'NO-Mask' or currentClass == 'NO-Safety Vest':\n",
    "                    #         MyColor = (0, 0, 255)\n",
    "                    #     else :\n",
    "                    #         MyColor = (255, 0, 0)\n",
    "\n",
    "                    cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1 + 50), max(35, y1)), scale=0.8, thickness=1, colorB=MyColor, colorT= (255, 255, 255), colorR=MyColor, offset=5)\n",
    "                    # cv2.rectangle(img, (x1, y1), (x2, y2), MyColor, 3)\n",
    "\n",
    "    out.write(img)  # Write out the frame to the new video file\n",
    "\n",
    "    # cv2.imshow(\"Image\", img)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):  # break the loop on 'q' key press\n",
    "        # break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "- \n",
    "![image.png](2023-06-08%2011_02_04-Image.jpg)\n",
    "\n",
    "##### FREE YOUTUBE DOWNLOADER: https://youtube4kdownloader.com/download/clip/https%253A%252F%252Fwww.youtube.com%252Fwatch%253Fv%253DA0VUasvVHlQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Running:\n",
      ">>> \"+ \" \".join(cmd)\n",
      "Moviepy - Command successful\n"
     ]
    }
   ],
   "source": [
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
    "\n",
    "# Specify the start and end times in seconds\n",
    "start_time = 2*60 + 15\n",
    "end_time = 2*60 + 22\n",
    "\n",
    "# Specify the video file path\n",
    "video_file_path = r\"C:\\Users\\dimit\\Downloads\\DARKFEST 2023 IS BACK AND EVEN BIGGER THEN EVER!!!.mp4\"\n",
    "\n",
    "# Specify the output file name\n",
    "output_file_path = \"output_cropped.mp4\"\n",
    "\n",
    "# Extract the subclip\n",
    "ffmpeg_extract_subclip(video_file_path, start_time, end_time, targetname=output_file_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try giving a mask (region of interest) to YOLO\n",
    "\n",
    "- For launching a big jump always we have a straight section before to preload the suspension and optimize the body position\n",
    "- We can use a mask to crop the image and give it to YOLO to detect the jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(image, region):\n",
    "    height = image.shape[0]\n",
    "    mask = np.zeros_like(image) # mask with black pixels matching the dimensions of the image\n",
    "    cv2.fillPoly(mask, region, 255) # fill the triangle with white pixels\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d5145fb340>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('../MTB_dataset/test/images/2023-06-08 10_45_19-(190) DARKFEST 2020- WORLDS BIGGEST MTB JUMPS WITH NICO VINK - YouTube.jpg')\n",
    "img = cv2.resize(img, (700, 700))\n",
    "\n",
    "region = np.array([[(150, 300), (550, 300), (450, 100), (250, 100)]])\n",
    "mask = region_of_interest(img, region)\n",
    "\n",
    "plt.imshow(mask)\n",
    "\n",
    "masked_image = cv2.bitwise_and(img, region_of_interest(img, region))\n",
    "plt.imshow(masked_image, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 704x704 5 jumps, 20 turns, 2065.8ms\n",
      "Speed: 9.2ms preprocess, 2065.8ms inference, 5.3ms postprocess per image at shape (1, 3, 704, 704)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = YOLO('bestmb.pt')\n",
    "\n",
    "classNames = ['turn', 'jump']\n",
    "\n",
    "MyColor = (0, 0, 255)\n",
    "\n",
    "img = cv2.imread('../MTB_dataset/test/images/2023-06-08 10_45_19-(190) DARKFEST 2020- WORLDS BIGGEST MTB JUMPS WITH NICO VINK - YouTube.jpg')\n",
    "img = cv2.resize(img, (700, 700))\n",
    "region = np.array([[(150, 300), (550, 300), (450, 100), (250, 100)]])\n",
    "masked_image = cv2.bitwise_and(img, region_of_interest(img, region))\n",
    "plt.imshow(masked_image, cmap='gray')\n",
    "\n",
    "results = model(masked_image, stream=True)\n",
    "\n",
    "for r in results:\n",
    "    boxes = r.boxes\n",
    "    for box in boxes:\n",
    "            \n",
    "            # Confidence\n",
    "            conf = math.ceil((box.conf[0] * 100))/100\n",
    "\n",
    "            if conf > 0.975:\n",
    "                # Bounding Box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "                bbox = (x1, y1, w, h)\n",
    "                # cv2.rectangle(image, (x1, y1), (x2, y2), (150, 0, 255), 1)\n",
    "                cvzone.cornerRect(img, (bbox), 20, rt = 2)\n",
    "                \n",
    "\n",
    "            \n",
    "                # Class Name\n",
    "                cls = int(box.cls[0])\n",
    "                currentClass = classNames[cls]\n",
    "\n",
    "                # if conf > 0.5:\n",
    "\n",
    "                #     if currentClass == 'Hardhat' or currentClass == 'Mask' or currentClass == 'Safety Vest':\n",
    "                #         MyColor = (0, 255, 0)\n",
    "                #     elif currentClass == 'NO-Hardhat' or currentClass == 'NO-Mask' or currentClass == 'NO-Safety Vest':\n",
    "                #         MyColor = (0, 0, 255)\n",
    "                #     else :\n",
    "                #         MyColor = (255, 0, 0)\n",
    "\n",
    "                cvzone.putTextRect(img, f'{classNames[cls]} {conf}', (max(0, x1 + 50), max(35, y1)), scale=0.8, thickness=1, colorB=MyColor, colorT= (255, 255, 255), colorR=MyColor, offset=5)\n",
    "                # cv2.rectangle(img, (x1, y1), (x2, y2), MyColor, 3)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "while True:\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):  # break the loop on 'q' key press\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](12.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
